{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameter\n",
    "nb_batch = 256\n",
    "num_classes = 10\n",
    "nb_epochs = 200\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "x_train dtype: uint8\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# The data, shuffled and split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_train dtype:', x_train.dtype)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "normalization_layer = keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
    "data_augmentation_layer = Sequential([\n",
    "    keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
    "    keras.layers.experimental.preprocessing.RandomRotation(0.1)\n",
    "])\n",
    "\n",
    "\n",
    "def prepare(ds, shuffle=False, augment=False):\n",
    "    # Resize and rescale all datasets\n",
    "    ds = ds.map(lambda x, y: (normalization_layer(x), y),\n",
    "                num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(1000)\n",
    "\n",
    "    # Batch all datasets\n",
    "    ds = ds.batch(nb_batch)\n",
    "\n",
    "    # Use data augmentation only on the training set\n",
    "    if augment:\n",
    "        ds = ds.map(lambda x, y: (data_augmentation_layer(x, training=True), y),\n",
    "                    num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    # Use buffered prefecting on all datasets\n",
    "    return ds.prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리\n",
    "y_train = y_train.reshape(-1)\n",
    "y_test = y_test.reshape(-1)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "\n",
    "train_ds = prepare(train_ds, shuffle=True, augment=True)\n",
    "test_ds = prepare(test_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModel(dropout_rate=0.0):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, [3, 3], padding='same',\n",
    "              activation='relu', input_shape=x_train.shape[1:]))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(Conv2D(32, [3, 3], padding='same', activation='relu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(Conv2D(32, [3, 3], padding='same', activation='relu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(MaxPooling2D([2, 2], strides=(2, 2), padding='same'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Conv2D(64, [3, 3], padding='same', activation='relu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(Conv2D(64, [3, 3], padding='same', activation='relu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(Conv2D(64, [3, 3], padding='same', activation='relu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(MaxPooling2D([2, 2], strides=(2, 2), padding='same'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Conv2D(128, [3, 3], padding='same', activation='relu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(Conv2D(128, [3, 3], padding='same', activation='relu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(Conv2D(128, [3, 3], padding='same', activation='relu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(MaxPooling2D([2, 2], strides=(2, 2), padding='same'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Conv2D(256, [3, 3], padding='same', activation='relu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(Conv2D(256, [3, 3], padding='same', activation='relu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(Conv2D(256, [3, 3], padding='same', activation='relu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(MaxPooling2D([2, 2], strides=(2, 2), padding='same'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Conv2D(512, [3, 3], padding='same', activation='relu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(Conv2D(512, [3, 3], padding='same', activation='relu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(Conv2D(512, [3, 3], padding='same', activation='relu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(MaxPooling2D([2, 2], strides=(2, 2), padding='same'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True,\n",
    "                                         monitor='val_loss')                                     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "196/196 [==============================] - 16s 57ms/step - loss: 1.8931 - accuracy: 0.2960 - val_loss: 3.0443 - val_accuracy: 0.1483\n",
      "Epoch 2/200\n",
      "196/196 [==============================] - 10s 52ms/step - loss: 1.4500 - accuracy: 0.4674 - val_loss: 2.1218 - val_accuracy: 0.3865\n",
      "Epoch 3/200\n",
      "196/196 [==============================] - 10s 52ms/step - loss: 1.2243 - accuracy: 0.5679 - val_loss: 1.4595 - val_accuracy: 0.5777\n",
      "Epoch 4/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 1.0676 - accuracy: 0.6292 - val_loss: 1.5313 - val_accuracy: 0.5920\n",
      "Epoch 5/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 0.9588 - accuracy: 0.6722 - val_loss: 1.0502 - val_accuracy: 0.6820\n",
      "Epoch 6/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 0.8799 - accuracy: 0.7025 - val_loss: 0.9962 - val_accuracy: 0.6954\n",
      "Epoch 7/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.8231 - accuracy: 0.7253 - val_loss: 0.9421 - val_accuracy: 0.7139\n",
      "Epoch 8/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.7632 - accuracy: 0.7464 - val_loss: 0.9042 - val_accuracy: 0.7178\n",
      "Epoch 9/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.7247 - accuracy: 0.7589 - val_loss: 0.8286 - val_accuracy: 0.7422\n",
      "Epoch 10/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.6888 - accuracy: 0.7722 - val_loss: 0.8722 - val_accuracy: 0.7307\n",
      "Epoch 11/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.7055 - accuracy: 0.7696 - val_loss: 0.7531 - val_accuracy: 0.7694\n",
      "Epoch 12/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.6544 - accuracy: 0.7862 - val_loss: 0.6019 - val_accuracy: 0.8013\n",
      "Epoch 13/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.6009 - accuracy: 0.8029 - val_loss: 0.6917 - val_accuracy: 0.7830\n",
      "Epoch 14/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.5853 - accuracy: 0.8065 - val_loss: 0.6364 - val_accuracy: 0.7912\n",
      "Epoch 15/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.5501 - accuracy: 0.8194 - val_loss: 0.5857 - val_accuracy: 0.8123\n",
      "Epoch 16/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.5328 - accuracy: 0.8251 - val_loss: 0.6061 - val_accuracy: 0.8057\n",
      "Epoch 17/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.5112 - accuracy: 0.8306 - val_loss: 0.6328 - val_accuracy: 0.8018\n",
      "Epoch 18/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.5317 - accuracy: 0.8269 - val_loss: 0.5782 - val_accuracy: 0.8166\n",
      "Epoch 19/200\n",
      "196/196 [==============================] - 11s 55ms/step - loss: 0.4924 - accuracy: 0.8367 - val_loss: 0.5366 - val_accuracy: 0.8312\n",
      "Epoch 20/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.4757 - accuracy: 0.8441 - val_loss: 0.5715 - val_accuracy: 0.8218\n",
      "Epoch 21/200\n",
      "196/196 [==============================] - 11s 55ms/step - loss: 0.4531 - accuracy: 0.8504 - val_loss: 0.5660 - val_accuracy: 0.8251\n",
      "Epoch 22/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.4463 - accuracy: 0.8541 - val_loss: 0.6140 - val_accuracy: 0.8126\n",
      "Epoch 23/200\n",
      "196/196 [==============================] - 11s 55ms/step - loss: 0.4347 - accuracy: 0.8561 - val_loss: 0.5913 - val_accuracy: 0.8231\n",
      "Epoch 24/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.4270 - accuracy: 0.8603 - val_loss: 0.5079 - val_accuracy: 0.8353\n",
      "Epoch 25/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.4378 - accuracy: 0.8564 - val_loss: 0.5439 - val_accuracy: 0.8284\n",
      "Epoch 26/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.4168 - accuracy: 0.8627 - val_loss: 0.4930 - val_accuracy: 0.8418\n",
      "Epoch 27/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.3910 - accuracy: 0.8700 - val_loss: 0.4983 - val_accuracy: 0.8454\n",
      "Epoch 28/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.3936 - accuracy: 0.8693 - val_loss: 0.4930 - val_accuracy: 0.8456\n",
      "Epoch 29/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.3923 - accuracy: 0.8715 - val_loss: 0.5658 - val_accuracy: 0.8353\n",
      "Epoch 30/200\n",
      "196/196 [==============================] - 11s 55ms/step - loss: 0.3619 - accuracy: 0.8801 - val_loss: 0.5089 - val_accuracy: 0.8430\n",
      "Epoch 31/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 0.3562 - accuracy: 0.8812 - val_loss: 0.4828 - val_accuracy: 0.8507\n",
      "Epoch 32/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.3471 - accuracy: 0.8834 - val_loss: 0.5309 - val_accuracy: 0.8462\n",
      "Epoch 33/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.3340 - accuracy: 0.8911 - val_loss: 0.4886 - val_accuracy: 0.8527\n",
      "Epoch 34/200\n",
      "196/196 [==============================] - 10s 52ms/step - loss: 0.3357 - accuracy: 0.8905 - val_loss: 0.5240 - val_accuracy: 0.8429\n",
      "Epoch 35/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.3226 - accuracy: 0.8919 - val_loss: 0.5349 - val_accuracy: 0.8352\n",
      "Epoch 36/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 0.3166 - accuracy: 0.8944 - val_loss: 0.4762 - val_accuracy: 0.8540\n",
      "Epoch 37/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 0.3088 - accuracy: 0.8989 - val_loss: 0.4773 - val_accuracy: 0.8523\n",
      "Epoch 38/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 0.3247 - accuracy: 0.8941 - val_loss: 0.5075 - val_accuracy: 0.8471\n",
      "Epoch 39/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 0.3004 - accuracy: 0.9005 - val_loss: 0.4901 - val_accuracy: 0.8591\n",
      "Epoch 40/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.2901 - accuracy: 0.9015 - val_loss: 0.5288 - val_accuracy: 0.8450\n",
      "Epoch 41/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.2918 - accuracy: 0.9043 - val_loss: 0.4706 - val_accuracy: 0.8621\n",
      "Epoch 42/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.2808 - accuracy: 0.9061 - val_loss: 0.4701 - val_accuracy: 0.8635\n",
      "Epoch 43/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.2778 - accuracy: 0.9071 - val_loss: 0.5039 - val_accuracy: 0.8526\n",
      "Epoch 44/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.4985 - accuracy: 0.8386 - val_loss: 0.5809 - val_accuracy: 0.8209\n",
      "Epoch 45/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.3597 - accuracy: 0.8812 - val_loss: 0.4755 - val_accuracy: 0.8521\n",
      "Epoch 46/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.3041 - accuracy: 0.8992 - val_loss: 0.4307 - val_accuracy: 0.8687\n",
      "Epoch 47/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.2789 - accuracy: 0.9063 - val_loss: 0.4859 - val_accuracy: 0.8562\n",
      "Epoch 48/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.2619 - accuracy: 0.9135 - val_loss: 0.4778 - val_accuracy: 0.8583\n",
      "Epoch 49/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.2544 - accuracy: 0.9156 - val_loss: 0.5044 - val_accuracy: 0.8565\n",
      "Epoch 50/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.2411 - accuracy: 0.9208 - val_loss: 0.4863 - val_accuracy: 0.8676\n",
      "Epoch 51/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.2438 - accuracy: 0.9191 - val_loss: 0.4913 - val_accuracy: 0.8616\n",
      "Epoch 52/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.2723 - accuracy: 0.9098 - val_loss: 0.5127 - val_accuracy: 0.8361\n",
      "Epoch 53/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 0.2816 - accuracy: 0.9072 - val_loss: 0.8263 - val_accuracy: 0.7769\n",
      "Epoch 54/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.4809 - accuracy: 0.8465 - val_loss: 2.0296 - val_accuracy: 0.6206\n",
      "Epoch 55/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.4349 - accuracy: 0.8544 - val_loss: 0.5035 - val_accuracy: 0.8429\n",
      "Epoch 56/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.3321 - accuracy: 0.8885 - val_loss: 0.4832 - val_accuracy: 0.8483\n",
      "40/40 - 1s - loss: 0.4307 - accuracy: 0.8687\n",
      "Epoch 1/200\n",
      "196/196 [==============================] - 12s 54ms/step - loss: 1.8747 - accuracy: 0.2938 - val_loss: 4.0875 - val_accuracy: 0.1061\n",
      "Epoch 2/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 1.4344 - accuracy: 0.4790 - val_loss: 2.2994 - val_accuracy: 0.4068\n",
      "Epoch 3/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 1.2392 - accuracy: 0.5646 - val_loss: 1.5502 - val_accuracy: 0.5656\n",
      "Epoch 4/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 1.1018 - accuracy: 0.6203 - val_loss: 1.5399 - val_accuracy: 0.5757\n",
      "Epoch 5/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 1.0126 - accuracy: 0.6557 - val_loss: 1.2502 - val_accuracy: 0.6408\n",
      "Epoch 6/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 0.9484 - accuracy: 0.6791 - val_loss: 1.2146 - val_accuracy: 0.6467\n",
      "Epoch 7/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 0.8912 - accuracy: 0.7043 - val_loss: 1.3389 - val_accuracy: 0.6591\n",
      "Epoch 8/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.8330 - accuracy: 0.7248 - val_loss: 0.9232 - val_accuracy: 0.7119\n",
      "Epoch 9/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 0.7880 - accuracy: 0.7397 - val_loss: 0.9676 - val_accuracy: 0.6994\n",
      "Epoch 10/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 0.7484 - accuracy: 0.7541 - val_loss: 0.9413 - val_accuracy: 0.7217\n",
      "Epoch 11/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.7153 - accuracy: 0.7654 - val_loss: 1.0213 - val_accuracy: 0.6943\n",
      "Epoch 12/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.6894 - accuracy: 0.7733 - val_loss: 0.7464 - val_accuracy: 0.7631\n",
      "Epoch 13/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.6609 - accuracy: 0.7827 - val_loss: 0.7158 - val_accuracy: 0.7794\n",
      "Epoch 14/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.6452 - accuracy: 0.7898 - val_loss: 0.7305 - val_accuracy: 0.7782\n",
      "Epoch 15/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 0.6161 - accuracy: 0.7968 - val_loss: 0.6970 - val_accuracy: 0.7866\n",
      "Epoch 16/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 0.6083 - accuracy: 0.8014 - val_loss: 0.6266 - val_accuracy: 0.7998\n",
      "Epoch 17/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.5759 - accuracy: 0.8113 - val_loss: 0.6578 - val_accuracy: 0.7973\n",
      "Epoch 18/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.5673 - accuracy: 0.8158 - val_loss: 0.5694 - val_accuracy: 0.8180\n",
      "Epoch 19/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.5496 - accuracy: 0.8197 - val_loss: 0.6146 - val_accuracy: 0.8056\n",
      "Epoch 20/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.5343 - accuracy: 0.8253 - val_loss: 0.6263 - val_accuracy: 0.8068\n",
      "Epoch 21/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.5274 - accuracy: 0.8292 - val_loss: 0.6358 - val_accuracy: 0.8021\n",
      "Epoch 22/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.5083 - accuracy: 0.8343 - val_loss: 0.5688 - val_accuracy: 0.8115\n",
      "Epoch 23/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.4983 - accuracy: 0.8364 - val_loss: 0.5420 - val_accuracy: 0.8326\n",
      "Epoch 24/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.4911 - accuracy: 0.8393 - val_loss: 0.6191 - val_accuracy: 0.8134\n",
      "Epoch 25/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.4785 - accuracy: 0.8448 - val_loss: 0.5375 - val_accuracy: 0.8334\n",
      "Epoch 26/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.4701 - accuracy: 0.8472 - val_loss: 0.5173 - val_accuracy: 0.8373\n",
      "Epoch 27/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.4558 - accuracy: 0.8528 - val_loss: 0.5164 - val_accuracy: 0.8349\n",
      "Epoch 28/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.4492 - accuracy: 0.8535 - val_loss: 0.5467 - val_accuracy: 0.8297\n",
      "Epoch 29/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.4361 - accuracy: 0.8564 - val_loss: 0.5283 - val_accuracy: 0.8354\n",
      "Epoch 30/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 0.4303 - accuracy: 0.8581 - val_loss: 0.5629 - val_accuracy: 0.8362\n",
      "Epoch 31/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.4255 - accuracy: 0.8598 - val_loss: 0.4804 - val_accuracy: 0.8460\n",
      "Epoch 32/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.4116 - accuracy: 0.8638 - val_loss: 0.5031 - val_accuracy: 0.8505\n",
      "Epoch 33/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.4119 - accuracy: 0.8654 - val_loss: 0.5305 - val_accuracy: 0.8432\n",
      "Epoch 34/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.4076 - accuracy: 0.8661 - val_loss: 0.5135 - val_accuracy: 0.8438\n",
      "Epoch 35/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.3967 - accuracy: 0.8702 - val_loss: 0.4623 - val_accuracy: 0.8484\n",
      "Epoch 36/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.3916 - accuracy: 0.8703 - val_loss: 0.4845 - val_accuracy: 0.8530\n",
      "Epoch 37/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.3817 - accuracy: 0.8735 - val_loss: 0.4948 - val_accuracy: 0.8506\n",
      "Epoch 38/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.3793 - accuracy: 0.8739 - val_loss: 0.4735 - val_accuracy: 0.8489\n",
      "Epoch 39/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.3682 - accuracy: 0.8755 - val_loss: 0.4236 - val_accuracy: 0.8688\n",
      "Epoch 40/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.3635 - accuracy: 0.8804 - val_loss: 0.4328 - val_accuracy: 0.8677\n",
      "Epoch 41/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.3576 - accuracy: 0.8828 - val_loss: 0.5125 - val_accuracy: 0.8504\n",
      "Epoch 42/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 0.3528 - accuracy: 0.8836 - val_loss: 0.4648 - val_accuracy: 0.8588\n",
      "Epoch 43/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.3453 - accuracy: 0.8854 - val_loss: 0.4618 - val_accuracy: 0.8599\n",
      "Epoch 44/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.3382 - accuracy: 0.8885 - val_loss: 0.4762 - val_accuracy: 0.8561\n",
      "Epoch 45/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 0.3329 - accuracy: 0.8895 - val_loss: 0.4599 - val_accuracy: 0.8570\n",
      "Epoch 46/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.3286 - accuracy: 0.8919 - val_loss: 0.4459 - val_accuracy: 0.8645\n",
      "Epoch 47/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.3255 - accuracy: 0.8911 - val_loss: 0.4319 - val_accuracy: 0.8667\n",
      "Epoch 48/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 0.3189 - accuracy: 0.8941 - val_loss: 0.4458 - val_accuracy: 0.8617\n",
      "Epoch 49/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 0.3198 - accuracy: 0.8926 - val_loss: 0.4521 - val_accuracy: 0.8577\n",
      "40/40 - 1s - loss: 0.4236 - accuracy: 0.8688\n",
      "Epoch 1/200\n",
      "196/196 [==============================] - 12s 54ms/step - loss: 1.9119 - accuracy: 0.2737 - val_loss: 4.7526 - val_accuracy: 0.1000\n",
      "Epoch 2/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 1.5063 - accuracy: 0.4432 - val_loss: 2.5305 - val_accuracy: 0.2631\n",
      "Epoch 3/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 1.3291 - accuracy: 0.5277 - val_loss: 1.5990 - val_accuracy: 0.5537\n",
      "Epoch 4/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 1.1879 - accuracy: 0.5863 - val_loss: 1.8377 - val_accuracy: 0.5431\n",
      "Epoch 5/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 1.0960 - accuracy: 0.6248 - val_loss: 1.7556 - val_accuracy: 0.5494\n",
      "Epoch 6/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 1.0261 - accuracy: 0.6492 - val_loss: 1.0741 - val_accuracy: 0.6601\n",
      "Epoch 7/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.9730 - accuracy: 0.6725 - val_loss: 1.2870 - val_accuracy: 0.6319\n",
      "Epoch 8/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.9242 - accuracy: 0.6907 - val_loss: 1.0792 - val_accuracy: 0.6794\n",
      "Epoch 9/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.8784 - accuracy: 0.7102 - val_loss: 0.8768 - val_accuracy: 0.7171\n",
      "Epoch 10/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.8424 - accuracy: 0.7237 - val_loss: 0.8810 - val_accuracy: 0.7134\n",
      "Epoch 11/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.8130 - accuracy: 0.7344 - val_loss: 0.7878 - val_accuracy: 0.7535\n",
      "Epoch 12/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.7738 - accuracy: 0.7462 - val_loss: 0.8330 - val_accuracy: 0.7435\n",
      "Epoch 13/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.7481 - accuracy: 0.7559 - val_loss: 0.7608 - val_accuracy: 0.7583\n",
      "Epoch 14/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.7273 - accuracy: 0.7657 - val_loss: 0.6782 - val_accuracy: 0.7778\n",
      "Epoch 15/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.6963 - accuracy: 0.7712 - val_loss: 0.7979 - val_accuracy: 0.7538\n",
      "Epoch 16/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.6899 - accuracy: 0.7748 - val_loss: 0.6129 - val_accuracy: 0.8031\n",
      "Epoch 17/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.6643 - accuracy: 0.7855 - val_loss: 0.6346 - val_accuracy: 0.7991\n",
      "Epoch 18/200\n",
      "196/196 [==============================] - 10s 52ms/step - loss: 0.6444 - accuracy: 0.7917 - val_loss: 0.6271 - val_accuracy: 0.7984\n",
      "Epoch 19/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.6284 - accuracy: 0.7966 - val_loss: 0.6286 - val_accuracy: 0.8041\n",
      "Epoch 20/200\n",
      "196/196 [==============================] - 10s 52ms/step - loss: 0.6126 - accuracy: 0.8028 - val_loss: 0.7552 - val_accuracy: 0.7719\n",
      "Epoch 21/200\n",
      "196/196 [==============================] - 10s 52ms/step - loss: 0.5986 - accuracy: 0.8074 - val_loss: 0.5562 - val_accuracy: 0.8212\n",
      "Epoch 22/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.5888 - accuracy: 0.8082 - val_loss: 0.5794 - val_accuracy: 0.8146\n",
      "Epoch 23/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.5725 - accuracy: 0.8149 - val_loss: 0.5839 - val_accuracy: 0.8202\n",
      "Epoch 24/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.5514 - accuracy: 0.8204 - val_loss: 0.6855 - val_accuracy: 0.7891\n",
      "Epoch 25/200\n",
      "196/196 [==============================] - 10s 52ms/step - loss: 0.5477 - accuracy: 0.8206 - val_loss: 0.5329 - val_accuracy: 0.8278\n",
      "Epoch 26/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.5516 - accuracy: 0.8223 - val_loss: 0.5185 - val_accuracy: 0.8390\n",
      "Epoch 27/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.5356 - accuracy: 0.8261 - val_loss: 0.5513 - val_accuracy: 0.8263\n",
      "Epoch 28/200\n",
      "196/196 [==============================] - 10s 52ms/step - loss: 0.5195 - accuracy: 0.8316 - val_loss: 0.5117 - val_accuracy: 0.8391\n",
      "Epoch 29/200\n",
      "196/196 [==============================] - 10s 52ms/step - loss: 0.5075 - accuracy: 0.8339 - val_loss: 0.5144 - val_accuracy: 0.8319\n",
      "Epoch 30/200\n",
      "196/196 [==============================] - 10s 52ms/step - loss: 0.4970 - accuracy: 0.8384 - val_loss: 0.4950 - val_accuracy: 0.8430\n",
      "Epoch 31/200\n",
      "196/196 [==============================] - 10s 52ms/step - loss: 0.4879 - accuracy: 0.8406 - val_loss: 0.5330 - val_accuracy: 0.8349\n",
      "Epoch 32/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.4794 - accuracy: 0.8430 - val_loss: 0.5188 - val_accuracy: 0.8346\n",
      "Epoch 33/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.4720 - accuracy: 0.8483 - val_loss: 0.5124 - val_accuracy: 0.8367\n",
      "Epoch 34/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.4891 - accuracy: 0.8406 - val_loss: 0.5079 - val_accuracy: 0.8403\n",
      "Epoch 35/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.4642 - accuracy: 0.8483 - val_loss: 0.5021 - val_accuracy: 0.8516\n",
      "Epoch 36/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.4505 - accuracy: 0.8532 - val_loss: 0.4919 - val_accuracy: 0.8472\n",
      "Epoch 37/200\n",
      "196/196 [==============================] - 10s 52ms/step - loss: 0.4384 - accuracy: 0.8565 - val_loss: 0.5054 - val_accuracy: 0.8480\n",
      "Epoch 38/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.4363 - accuracy: 0.8568 - val_loss: 0.5618 - val_accuracy: 0.8364\n",
      "Epoch 39/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.4301 - accuracy: 0.8591 - val_loss: 0.5231 - val_accuracy: 0.8308\n",
      "Epoch 40/200\n",
      "196/196 [==============================] - 10s 52ms/step - loss: 0.4232 - accuracy: 0.8604 - val_loss: 0.4821 - val_accuracy: 0.8493\n",
      "Epoch 41/200\n",
      "196/196 [==============================] - 10s 52ms/step - loss: 0.4202 - accuracy: 0.8618 - val_loss: 0.4403 - val_accuracy: 0.8582\n",
      "Epoch 42/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.4156 - accuracy: 0.8626 - val_loss: 0.4565 - val_accuracy: 0.8556\n",
      "Epoch 43/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.4041 - accuracy: 0.8665 - val_loss: 0.5089 - val_accuracy: 0.8497\n",
      "Epoch 44/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.3996 - accuracy: 0.8670 - val_loss: 0.5349 - val_accuracy: 0.8355\n",
      "Epoch 45/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.3975 - accuracy: 0.8697 - val_loss: 0.4785 - val_accuracy: 0.8550\n",
      "Epoch 46/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.3980 - accuracy: 0.8687 - val_loss: 0.4907 - val_accuracy: 0.8563\n",
      "Epoch 47/200\n",
      "196/196 [==============================] - 10s 52ms/step - loss: 0.3837 - accuracy: 0.8748 - val_loss: 0.4911 - val_accuracy: 0.8527\n",
      "Epoch 48/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.3845 - accuracy: 0.8752 - val_loss: 0.4519 - val_accuracy: 0.8556\n",
      "Epoch 49/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.3729 - accuracy: 0.8749 - val_loss: 0.4488 - val_accuracy: 0.8604\n",
      "Epoch 50/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.3785 - accuracy: 0.8745 - val_loss: 0.4735 - val_accuracy: 0.8584\n",
      "Epoch 51/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.3670 - accuracy: 0.8784 - val_loss: 0.4281 - val_accuracy: 0.8696\n",
      "Epoch 52/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.3669 - accuracy: 0.8806 - val_loss: 0.4241 - val_accuracy: 0.8683\n",
      "Epoch 53/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.3691 - accuracy: 0.8796 - val_loss: 0.4612 - val_accuracy: 0.8555\n",
      "Epoch 54/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.3552 - accuracy: 0.8826 - val_loss: 0.4393 - val_accuracy: 0.8676\n",
      "Epoch 55/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.3531 - accuracy: 0.8823 - val_loss: 0.4223 - val_accuracy: 0.8702\n",
      "Epoch 56/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 0.3477 - accuracy: 0.8855 - val_loss: 0.4087 - val_accuracy: 0.8727\n",
      "Epoch 57/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.3460 - accuracy: 0.8864 - val_loss: 0.3991 - val_accuracy: 0.8761\n",
      "Epoch 58/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.3416 - accuracy: 0.8854 - val_loss: 0.4066 - val_accuracy: 0.8724\n",
      "Epoch 59/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.3407 - accuracy: 0.8870 - val_loss: 0.4469 - val_accuracy: 0.8595\n",
      "Epoch 60/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.3383 - accuracy: 0.8886 - val_loss: 0.5053 - val_accuracy: 0.8543\n",
      "Epoch 61/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.3303 - accuracy: 0.8901 - val_loss: 0.4480 - val_accuracy: 0.8708\n",
      "Epoch 62/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.3316 - accuracy: 0.8898 - val_loss: 0.4795 - val_accuracy: 0.8611\n",
      "Epoch 63/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.3206 - accuracy: 0.8937 - val_loss: 0.4467 - val_accuracy: 0.8671\n",
      "Epoch 64/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.3281 - accuracy: 0.8914 - val_loss: 0.4223 - val_accuracy: 0.8722\n",
      "Epoch 65/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.3156 - accuracy: 0.8957 - val_loss: 0.4675 - val_accuracy: 0.8635\n",
      "Epoch 66/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.3135 - accuracy: 0.8969 - val_loss: 0.4225 - val_accuracy: 0.8716\n",
      "Epoch 67/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.3140 - accuracy: 0.8956 - val_loss: 0.4305 - val_accuracy: 0.8680\n",
      "40/40 - 1s - loss: 0.3991 - accuracy: 0.8761\n",
      "Epoch 1/200\n",
      "196/196 [==============================] - 12s 54ms/step - loss: 2.0992 - accuracy: 0.1982 - val_loss: 2.6632 - val_accuracy: 0.1046\n",
      "Epoch 2/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 1.6876 - accuracy: 0.3469 - val_loss: 3.1806 - val_accuracy: 0.2097\n",
      "Epoch 3/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 1.5134 - accuracy: 0.4492 - val_loss: 2.5487 - val_accuracy: 0.3708\n",
      "Epoch 4/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 1.3710 - accuracy: 0.5176 - val_loss: 1.9723 - val_accuracy: 0.4479\n",
      "Epoch 5/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 1.2654 - accuracy: 0.5605 - val_loss: 1.6059 - val_accuracy: 0.5342\n",
      "Epoch 6/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 1.1759 - accuracy: 0.5938 - val_loss: 1.8444 - val_accuracy: 0.5297\n",
      "Epoch 7/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 1.1194 - accuracy: 0.6160 - val_loss: 1.4308 - val_accuracy: 0.5849\n",
      "Epoch 8/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 1.0586 - accuracy: 0.6448 - val_loss: 1.4291 - val_accuracy: 0.5873\n",
      "Epoch 9/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 1.0096 - accuracy: 0.6612 - val_loss: 0.9526 - val_accuracy: 0.6923\n",
      "Epoch 10/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 0.9602 - accuracy: 0.6792 - val_loss: 1.0401 - val_accuracy: 0.6608\n",
      "Epoch 11/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.9319 - accuracy: 0.6923 - val_loss: 1.0894 - val_accuracy: 0.6476\n",
      "Epoch 12/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.9030 - accuracy: 0.7019 - val_loss: 0.9855 - val_accuracy: 0.6913\n",
      "Epoch 13/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.8788 - accuracy: 0.7121 - val_loss: 1.1519 - val_accuracy: 0.6740\n",
      "Epoch 14/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.8406 - accuracy: 0.7245 - val_loss: 0.8476 - val_accuracy: 0.7196\n",
      "Epoch 15/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.8111 - accuracy: 0.7325 - val_loss: 0.9184 - val_accuracy: 0.7205\n",
      "Epoch 16/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.7956 - accuracy: 0.7413 - val_loss: 0.8024 - val_accuracy: 0.7482\n",
      "Epoch 17/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.7751 - accuracy: 0.7470 - val_loss: 0.7074 - val_accuracy: 0.7724\n",
      "Epoch 18/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.7495 - accuracy: 0.7547 - val_loss: 0.7380 - val_accuracy: 0.7647\n",
      "Epoch 19/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.7311 - accuracy: 0.7625 - val_loss: 0.7330 - val_accuracy: 0.7596\n",
      "Epoch 20/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.7172 - accuracy: 0.7675 - val_loss: 0.8006 - val_accuracy: 0.7527\n",
      "Epoch 21/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.6992 - accuracy: 0.7732 - val_loss: 0.6609 - val_accuracy: 0.7899\n",
      "Epoch 22/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.6826 - accuracy: 0.7796 - val_loss: 0.6588 - val_accuracy: 0.7949\n",
      "Epoch 23/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.6666 - accuracy: 0.7842 - val_loss: 0.6366 - val_accuracy: 0.8000\n",
      "Epoch 24/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.6483 - accuracy: 0.7891 - val_loss: 0.6910 - val_accuracy: 0.7842\n",
      "Epoch 25/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.6428 - accuracy: 0.7917 - val_loss: 0.6216 - val_accuracy: 0.7999\n",
      "Epoch 26/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.6299 - accuracy: 0.7949 - val_loss: 0.6520 - val_accuracy: 0.7946\n",
      "Epoch 27/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.6226 - accuracy: 0.7986 - val_loss: 0.6810 - val_accuracy: 0.7849\n",
      "Epoch 28/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.6065 - accuracy: 0.8037 - val_loss: 0.6201 - val_accuracy: 0.8040\n",
      "Epoch 29/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.6020 - accuracy: 0.8043 - val_loss: 0.5817 - val_accuracy: 0.8110\n",
      "Epoch 30/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.6005 - accuracy: 0.8038 - val_loss: 0.5787 - val_accuracy: 0.8115\n",
      "Epoch 31/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.5873 - accuracy: 0.8086 - val_loss: 0.5836 - val_accuracy: 0.8114\n",
      "Epoch 32/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.5782 - accuracy: 0.8133 - val_loss: 0.6372 - val_accuracy: 0.8042\n",
      "Epoch 33/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.5629 - accuracy: 0.8168 - val_loss: 0.6287 - val_accuracy: 0.8070\n",
      "Epoch 34/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.5573 - accuracy: 0.8177 - val_loss: 0.5345 - val_accuracy: 0.8278\n",
      "Epoch 35/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.5599 - accuracy: 0.8170 - val_loss: 0.5296 - val_accuracy: 0.8285\n",
      "Epoch 36/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.5375 - accuracy: 0.8258 - val_loss: 0.6860 - val_accuracy: 0.7960\n",
      "Epoch 37/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.6324 - accuracy: 0.7978 - val_loss: 1.3174 - val_accuracy: 0.7178\n",
      "Epoch 38/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.6187 - accuracy: 0.7993 - val_loss: 0.5537 - val_accuracy: 0.8255\n",
      "Epoch 39/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.5516 - accuracy: 0.8190 - val_loss: 0.5920 - val_accuracy: 0.8165\n",
      "Epoch 40/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.5293 - accuracy: 0.8259 - val_loss: 0.5295 - val_accuracy: 0.8334\n",
      "Epoch 41/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.5083 - accuracy: 0.8343 - val_loss: 0.4935 - val_accuracy: 0.8417\n",
      "Epoch 42/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 0.5081 - accuracy: 0.8328 - val_loss: 0.5245 - val_accuracy: 0.8294\n",
      "Epoch 43/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.5023 - accuracy: 0.8336 - val_loss: 0.4728 - val_accuracy: 0.8485\n",
      "Epoch 44/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.4963 - accuracy: 0.8371 - val_loss: 0.5638 - val_accuracy: 0.8234\n",
      "Epoch 45/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 0.4956 - accuracy: 0.8372 - val_loss: 0.4886 - val_accuracy: 0.8453\n",
      "Epoch 46/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.4801 - accuracy: 0.8415 - val_loss: 0.5418 - val_accuracy: 0.8370\n",
      "Epoch 47/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.4729 - accuracy: 0.8441 - val_loss: 0.4716 - val_accuracy: 0.8498\n",
      "Epoch 48/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 0.4689 - accuracy: 0.8468 - val_loss: 0.5378 - val_accuracy: 0.8324\n",
      "Epoch 49/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.4861 - accuracy: 0.8401 - val_loss: 0.6016 - val_accuracy: 0.8138\n",
      "Epoch 50/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 0.7486 - accuracy: 0.7690 - val_loss: 0.5987 - val_accuracy: 0.8212\n",
      "Epoch 51/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.5459 - accuracy: 0.8237 - val_loss: 0.5162 - val_accuracy: 0.8438\n",
      "Epoch 52/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.5705 - accuracy: 0.8193 - val_loss: 1.5374 - val_accuracy: 0.4923\n",
      "Epoch 53/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 0.8440 - accuracy: 0.7336 - val_loss: 0.6162 - val_accuracy: 0.8118\n",
      "Epoch 54/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 0.5691 - accuracy: 0.8119 - val_loss: 0.5175 - val_accuracy: 0.8311\n",
      "Epoch 55/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.5298 - accuracy: 0.8250 - val_loss: 0.4817 - val_accuracy: 0.8440\n",
      "Epoch 56/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 0.6842 - accuracy: 0.7864 - val_loss: 0.5613 - val_accuracy: 0.8191\n",
      "Epoch 57/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.6210 - accuracy: 0.7995 - val_loss: 0.6005 - val_accuracy: 0.8125\n",
      "40/40 - 1s - loss: 0.4716 - accuracy: 0.8498\n",
      "Epoch 1/200\n",
      "196/196 [==============================] - 12s 54ms/step - loss: 2.2150 - accuracy: 0.1819 - val_loss: 3.2130 - val_accuracy: 0.1061\n",
      "Epoch 2/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 1.8173 - accuracy: 0.2876 - val_loss: 3.3508 - val_accuracy: 0.1644\n",
      "Epoch 3/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 1.6685 - accuracy: 0.3626 - val_loss: 1.5734 - val_accuracy: 0.4269\n",
      "Epoch 4/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 1.5531 - accuracy: 0.4209 - val_loss: 1.8698 - val_accuracy: 0.4191\n",
      "Epoch 5/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 1.4431 - accuracy: 0.4790 - val_loss: 1.6033 - val_accuracy: 0.4974\n",
      "Epoch 6/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 1.3555 - accuracy: 0.5233 - val_loss: 1.8898 - val_accuracy: 0.4679\n",
      "Epoch 7/200\n",
      "196/196 [==============================] - 10s 52ms/step - loss: 1.2749 - accuracy: 0.5575 - val_loss: 1.2578 - val_accuracy: 0.5861\n",
      "Epoch 8/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 1.2078 - accuracy: 0.5870 - val_loss: 1.2691 - val_accuracy: 0.6044\n",
      "Epoch 9/200\n",
      "196/196 [==============================] - 10s 52ms/step - loss: 1.1459 - accuracy: 0.6125 - val_loss: 1.3422 - val_accuracy: 0.5868\n",
      "Epoch 10/200\n",
      "196/196 [==============================] - 10s 52ms/step - loss: 1.1085 - accuracy: 0.6243 - val_loss: 1.5413 - val_accuracy: 0.5841\n",
      "Epoch 11/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 1.0674 - accuracy: 0.6399 - val_loss: 1.0578 - val_accuracy: 0.6678\n",
      "Epoch 12/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 1.0330 - accuracy: 0.6565 - val_loss: 1.1130 - val_accuracy: 0.6347\n",
      "Epoch 13/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.9973 - accuracy: 0.6672 - val_loss: 1.0143 - val_accuracy: 0.6813\n",
      "Epoch 14/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.9838 - accuracy: 0.6754 - val_loss: 1.0497 - val_accuracy: 0.6687\n",
      "Epoch 15/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.9929 - accuracy: 0.6744 - val_loss: 1.0089 - val_accuracy: 0.6883\n",
      "Epoch 16/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.9308 - accuracy: 0.6950 - val_loss: 0.8808 - val_accuracy: 0.7122\n",
      "Epoch 17/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.9000 - accuracy: 0.7049 - val_loss: 1.0139 - val_accuracy: 0.6772\n",
      "Epoch 18/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.8827 - accuracy: 0.7110 - val_loss: 0.8704 - val_accuracy: 0.7247\n",
      "Epoch 19/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.8517 - accuracy: 0.7217 - val_loss: 0.8521 - val_accuracy: 0.7291\n",
      "Epoch 20/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.8401 - accuracy: 0.7261 - val_loss: 0.7862 - val_accuracy: 0.7436\n",
      "Epoch 21/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.8585 - accuracy: 0.7238 - val_loss: 0.9974 - val_accuracy: 0.7342\n",
      "Epoch 22/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.8356 - accuracy: 0.7283 - val_loss: 0.8137 - val_accuracy: 0.7449\n",
      "Epoch 23/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.8660 - accuracy: 0.7225 - val_loss: 2.4939 - val_accuracy: 0.5325\n",
      "Epoch 24/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 1.1316 - accuracy: 0.6430 - val_loss: 1.5205 - val_accuracy: 0.5508\n",
      "Epoch 25/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.9764 - accuracy: 0.6823 - val_loss: 0.7106 - val_accuracy: 0.7675\n",
      "Epoch 26/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.8354 - accuracy: 0.7261 - val_loss: 0.7458 - val_accuracy: 0.7572\n",
      "Epoch 27/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.7901 - accuracy: 0.7417 - val_loss: 0.7963 - val_accuracy: 0.7528\n",
      "Epoch 28/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.7674 - accuracy: 0.7517 - val_loss: 0.7465 - val_accuracy: 0.7590\n",
      "Epoch 29/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.7487 - accuracy: 0.7552 - val_loss: 0.6998 - val_accuracy: 0.7769\n",
      "Epoch 30/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.7392 - accuracy: 0.7607 - val_loss: 0.7417 - val_accuracy: 0.7673\n",
      "Epoch 31/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.7708 - accuracy: 0.7516 - val_loss: 1.6149 - val_accuracy: 0.5560\n",
      "Epoch 32/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 1.0727 - accuracy: 0.6631 - val_loss: 1.2831 - val_accuracy: 0.5948\n",
      "Epoch 33/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.9199 - accuracy: 0.7006 - val_loss: 0.7076 - val_accuracy: 0.7680\n",
      "Epoch 34/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.7996 - accuracy: 0.7392 - val_loss: 0.7362 - val_accuracy: 0.7658\n",
      "Epoch 35/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.7508 - accuracy: 0.7530 - val_loss: 0.6942 - val_accuracy: 0.7798\n",
      "Epoch 36/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.7956 - accuracy: 0.7449 - val_loss: 1.2578 - val_accuracy: 0.5932\n",
      "Epoch 37/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.7945 - accuracy: 0.7401 - val_loss: 0.6742 - val_accuracy: 0.7796\n",
      "Epoch 38/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.7249 - accuracy: 0.7634 - val_loss: 0.7053 - val_accuracy: 0.7708\n",
      "Epoch 39/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.6871 - accuracy: 0.7760 - val_loss: 0.7038 - val_accuracy: 0.7838\n",
      "Epoch 40/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.7218 - accuracy: 0.7650 - val_loss: 0.7867 - val_accuracy: 0.7571\n",
      "Epoch 41/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.7272 - accuracy: 0.7634 - val_loss: 0.7551 - val_accuracy: 0.7694\n",
      "Epoch 42/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.6964 - accuracy: 0.7740 - val_loss: 0.6788 - val_accuracy: 0.7934\n",
      "Epoch 43/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.6682 - accuracy: 0.7832 - val_loss: 0.6631 - val_accuracy: 0.7967\n",
      "Epoch 44/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.6533 - accuracy: 0.7861 - val_loss: 0.6191 - val_accuracy: 0.8018\n",
      "Epoch 45/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.7960 - accuracy: 0.7438 - val_loss: 221.9154 - val_accuracy: 0.2002\n",
      "Epoch 46/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 0.9375 - accuracy: 0.6972 - val_loss: 1.0293 - val_accuracy: 0.6980\n",
      "Epoch 47/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.9068 - accuracy: 0.7047 - val_loss: 0.7030 - val_accuracy: 0.7671\n",
      "Epoch 48/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.7573 - accuracy: 0.7524 - val_loss: 0.6881 - val_accuracy: 0.7740\n",
      "Epoch 49/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.6951 - accuracy: 0.7711 - val_loss: 0.6435 - val_accuracy: 0.7924\n",
      "Epoch 50/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.6816 - accuracy: 0.7760 - val_loss: 0.5822 - val_accuracy: 0.8063\n",
      "Epoch 51/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 0.6628 - accuracy: 0.7847 - val_loss: 0.6273 - val_accuracy: 0.7949\n",
      "Epoch 52/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.6399 - accuracy: 0.7894 - val_loss: 0.6267 - val_accuracy: 0.7984\n",
      "Epoch 53/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.6401 - accuracy: 0.7911 - val_loss: 0.6220 - val_accuracy: 0.7956\n",
      "Epoch 54/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.8350 - accuracy: 0.7279 - val_loss: 0.6983 - val_accuracy: 0.7781\n",
      "Epoch 55/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 1.0963 - accuracy: 0.6503 - val_loss: 0.7255 - val_accuracy: 0.7612\n",
      "Epoch 56/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 0.8344 - accuracy: 0.7265 - val_loss: 0.6496 - val_accuracy: 0.7728\n",
      "Epoch 57/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.7256 - accuracy: 0.7612 - val_loss: 0.6182 - val_accuracy: 0.7984\n",
      "Epoch 58/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.6842 - accuracy: 0.7736 - val_loss: 0.6067 - val_accuracy: 0.8003\n",
      "Epoch 59/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.6759 - accuracy: 0.7783 - val_loss: 0.7744 - val_accuracy: 0.7429\n",
      "Epoch 60/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 0.8046 - accuracy: 0.7432 - val_loss: 0.9692 - val_accuracy: 0.7548\n",
      "40/40 - 1s - loss: 0.5822 - accuracy: 0.8063\n",
      "Epoch 1/200\n",
      "196/196 [==============================] - 12s 54ms/step - loss: 2.4399 - accuracy: 0.1369 - val_loss: 2.4680 - val_accuracy: 0.1003\n",
      "Epoch 2/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 2.0130 - accuracy: 0.2202 - val_loss: 2.5315 - val_accuracy: 0.1373\n",
      "Epoch 3/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 1.8435 - accuracy: 0.2770 - val_loss: 1.8078 - val_accuracy: 0.2974\n",
      "Epoch 4/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 1.7424 - accuracy: 0.3260 - val_loss: 1.7896 - val_accuracy: 0.3674\n",
      "Epoch 5/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 1.6406 - accuracy: 0.3837 - val_loss: 1.9210 - val_accuracy: 0.3756\n",
      "Epoch 6/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 1.5702 - accuracy: 0.4207 - val_loss: 1.4783 - val_accuracy: 0.4342\n",
      "Epoch 7/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 1.4875 - accuracy: 0.4616 - val_loss: 1.5604 - val_accuracy: 0.4548\n",
      "Epoch 8/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 1.4342 - accuracy: 0.4895 - val_loss: 1.9768 - val_accuracy: 0.4144\n",
      "Epoch 9/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 1.3803 - accuracy: 0.5217 - val_loss: 1.9734 - val_accuracy: 0.3814\n",
      "Epoch 10/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 1.3382 - accuracy: 0.5372 - val_loss: 1.6136 - val_accuracy: 0.5164\n",
      "Epoch 11/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 1.2933 - accuracy: 0.5564 - val_loss: 1.4669 - val_accuracy: 0.5494\n",
      "Epoch 12/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 1.2458 - accuracy: 0.5738 - val_loss: 1.3894 - val_accuracy: 0.5468\n",
      "Epoch 13/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 1.2141 - accuracy: 0.5873 - val_loss: 1.2638 - val_accuracy: 0.5903\n",
      "Epoch 14/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 1.1686 - accuracy: 0.6032 - val_loss: 1.2247 - val_accuracy: 0.6109\n",
      "Epoch 15/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 1.1678 - accuracy: 0.6092 - val_loss: 1.1323 - val_accuracy: 0.6277\n",
      "Epoch 16/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 1.1270 - accuracy: 0.6213 - val_loss: 1.1584 - val_accuracy: 0.6171\n",
      "Epoch 17/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 1.0962 - accuracy: 0.6337 - val_loss: 1.0604 - val_accuracy: 0.6544\n",
      "Epoch 18/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 1.0816 - accuracy: 0.6383 - val_loss: 1.3338 - val_accuracy: 0.5761\n",
      "Epoch 19/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 1.1124 - accuracy: 0.6292 - val_loss: 1.0953 - val_accuracy: 0.6352\n",
      "Epoch 20/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 1.0865 - accuracy: 0.6398 - val_loss: 1.4714 - val_accuracy: 0.5327\n",
      "Epoch 21/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 1.2284 - accuracy: 0.5945 - val_loss: 1.1277 - val_accuracy: 0.6367\n",
      "Epoch 22/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 1.2105 - accuracy: 0.5982 - val_loss: 1.1375 - val_accuracy: 0.6231\n",
      "Epoch 23/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 1.0570 - accuracy: 0.6446 - val_loss: 0.9856 - val_accuracy: 0.6730\n",
      "Epoch 24/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 1.0071 - accuracy: 0.6643 - val_loss: 0.9400 - val_accuracy: 0.6746\n",
      "Epoch 25/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 1.1428 - accuracy: 0.6226 - val_loss: 1.8658 - val_accuracy: 0.5553\n",
      "Epoch 26/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 1.0826 - accuracy: 0.6385 - val_loss: 1.0780 - val_accuracy: 0.6620\n",
      "Epoch 27/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 1.3262 - accuracy: 0.5652 - val_loss: 1.6276 - val_accuracy: 0.5167\n",
      "Epoch 28/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 1.1211 - accuracy: 0.6275 - val_loss: 0.9542 - val_accuracy: 0.6735\n",
      "Epoch 29/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 1.1816 - accuracy: 0.6099 - val_loss: 1.3387 - val_accuracy: 0.5603\n",
      "Epoch 30/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 1.0784 - accuracy: 0.6452 - val_loss: 1.0992 - val_accuracy: 0.6429\n",
      "Epoch 31/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 1.0072 - accuracy: 0.6651 - val_loss: 1.0006 - val_accuracy: 0.6787\n",
      "Epoch 32/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 0.9857 - accuracy: 0.6735 - val_loss: 1.1055 - val_accuracy: 0.6467\n",
      "Epoch 33/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 0.9692 - accuracy: 0.6793 - val_loss: 1.0325 - val_accuracy: 0.6890\n",
      "Epoch 34/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 1.1896 - accuracy: 0.6119 - val_loss: 1.1906 - val_accuracy: 0.6457\n",
      "40/40 - 1s - loss: 0.9400 - accuracy: 0.6746\n",
      "Epoch 1/200\n",
      "196/196 [==============================] - 12s 54ms/step - loss: 2.6256 - accuracy: 0.1063 - val_loss: 2.3033 - val_accuracy: 0.1037\n",
      "Epoch 2/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 2.2737 - accuracy: 0.1448 - val_loss: 2.3443 - val_accuracy: 0.1005\n",
      "Epoch 3/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 2.1406 - accuracy: 0.1721 - val_loss: 2.2849 - val_accuracy: 0.1291\n",
      "Epoch 4/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 2.0736 - accuracy: 0.1762 - val_loss: 2.1130 - val_accuracy: 0.1780\n",
      "Epoch 5/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 2.0142 - accuracy: 0.1868 - val_loss: 2.0528 - val_accuracy: 0.1883\n",
      "Epoch 6/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 2.0130 - accuracy: 0.1902 - val_loss: 2.3733 - val_accuracy: 0.1523\n",
      "Epoch 7/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 2.0206 - accuracy: 0.1807 - val_loss: 2.2179 - val_accuracy: 0.1611\n",
      "Epoch 8/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 1.9892 - accuracy: 0.1909 - val_loss: 2.0907 - val_accuracy: 0.1699\n",
      "Epoch 9/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 1.9671 - accuracy: 0.1990 - val_loss: 2.0177 - val_accuracy: 0.1913\n",
      "Epoch 10/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 1.9539 - accuracy: 0.2018 - val_loss: 1.9548 - val_accuracy: 0.1979\n",
      "Epoch 11/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 1.9328 - accuracy: 0.2109 - val_loss: 1.9349 - val_accuracy: 0.1924\n",
      "Epoch 12/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 1.9234 - accuracy: 0.2207 - val_loss: 2.2208 - val_accuracy: 0.1766\n",
      "Epoch 13/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 1.9033 - accuracy: 0.2339 - val_loss: 1.9029 - val_accuracy: 0.2421\n",
      "Epoch 14/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 1.8862 - accuracy: 0.2503 - val_loss: 1.8610 - val_accuracy: 0.2750\n",
      "Epoch 15/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 1.8530 - accuracy: 0.2746 - val_loss: 1.7953 - val_accuracy: 0.2850\n",
      "Epoch 16/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 1.8029 - accuracy: 0.2963 - val_loss: 1.7161 - val_accuracy: 0.3247\n",
      "Epoch 17/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 1.7585 - accuracy: 0.3174 - val_loss: 1.6912 - val_accuracy: 0.3223\n",
      "Epoch 18/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 1.7528 - accuracy: 0.3241 - val_loss: 1.6037 - val_accuracy: 0.3520\n",
      "Epoch 19/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 1.6996 - accuracy: 0.3515 - val_loss: 1.8323 - val_accuracy: 0.2901\n",
      "Epoch 20/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 1.7578 - accuracy: 0.3408 - val_loss: 1.6246 - val_accuracy: 0.3372\n",
      "Epoch 21/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 1.6856 - accuracy: 0.3637 - val_loss: 1.6344 - val_accuracy: 0.3666\n",
      "Epoch 22/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 1.6829 - accuracy: 0.3672 - val_loss: 1.7859 - val_accuracy: 0.3353\n",
      "Epoch 23/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 1.6167 - accuracy: 0.3902 - val_loss: 1.6638 - val_accuracy: 0.3463\n",
      "Epoch 24/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 1.5908 - accuracy: 0.4092 - val_loss: 1.5562 - val_accuracy: 0.4115\n",
      "Epoch 25/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 1.6401 - accuracy: 0.3946 - val_loss: 1.7098 - val_accuracy: 0.3557\n",
      "Epoch 26/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 1.5871 - accuracy: 0.4170 - val_loss: 1.5794 - val_accuracy: 0.4159\n",
      "Epoch 27/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 1.5419 - accuracy: 0.4372 - val_loss: 1.4934 - val_accuracy: 0.4444\n",
      "Epoch 28/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 1.5048 - accuracy: 0.4481 - val_loss: 1.4949 - val_accuracy: 0.4615\n",
      "Epoch 29/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 1.5397 - accuracy: 0.4484 - val_loss: 2.1042 - val_accuracy: 0.3196\n",
      "Epoch 30/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 1.5192 - accuracy: 0.4568 - val_loss: 2.1534 - val_accuracy: 0.3566\n",
      "Epoch 31/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 1.5392 - accuracy: 0.4540 - val_loss: 1.6756 - val_accuracy: 0.4292\n",
      "Epoch 32/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 1.4569 - accuracy: 0.4879 - val_loss: 1.5611 - val_accuracy: 0.4730\n",
      "Epoch 33/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 1.4551 - accuracy: 0.4889 - val_loss: 1.4892 - val_accuracy: 0.4700\n",
      "Epoch 34/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 1.5038 - accuracy: 0.4806 - val_loss: 1.6894 - val_accuracy: 0.4058\n",
      "Epoch 35/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 1.4736 - accuracy: 0.4909 - val_loss: 1.4052 - val_accuracy: 0.5225\n",
      "Epoch 36/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 1.3938 - accuracy: 0.5244 - val_loss: 1.5120 - val_accuracy: 0.5114\n",
      "Epoch 37/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 1.3517 - accuracy: 0.5386 - val_loss: 1.3374 - val_accuracy: 0.5255\n",
      "Epoch 38/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 1.4687 - accuracy: 0.4956 - val_loss: 1.3871 - val_accuracy: 0.5280\n",
      "Epoch 39/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 1.3978 - accuracy: 0.5192 - val_loss: 1.5966 - val_accuracy: 0.4892\n",
      "Epoch 40/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 1.3743 - accuracy: 0.5352 - val_loss: 1.3698 - val_accuracy: 0.5315\n",
      "Epoch 41/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 1.4145 - accuracy: 0.5177 - val_loss: 1.4088 - val_accuracy: 0.5518\n",
      "Epoch 42/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 1.3256 - accuracy: 0.5469 - val_loss: 1.2950 - val_accuracy: 0.5539\n",
      "Epoch 43/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 1.6008 - accuracy: 0.4584 - val_loss: 1.7524 - val_accuracy: 0.4122\n",
      "Epoch 44/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 1.4070 - accuracy: 0.5194 - val_loss: 1.6344 - val_accuracy: 0.4822\n",
      "Epoch 45/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 1.3993 - accuracy: 0.5253 - val_loss: 1.5986 - val_accuracy: 0.4661\n",
      "Epoch 46/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 1.3995 - accuracy: 0.5246 - val_loss: 1.3671 - val_accuracy: 0.5416\n",
      "Epoch 47/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 1.2884 - accuracy: 0.5614 - val_loss: 1.4136 - val_accuracy: 0.5296\n",
      "Epoch 48/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 1.2846 - accuracy: 0.5638 - val_loss: 1.3900 - val_accuracy: 0.5409\n",
      "Epoch 49/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 1.4789 - accuracy: 0.5076 - val_loss: 2.3045 - val_accuracy: 0.2785\n",
      "Epoch 50/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 1.6872 - accuracy: 0.4221 - val_loss: 1.5766 - val_accuracy: 0.4441\n",
      "Epoch 51/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 1.4891 - accuracy: 0.4835 - val_loss: 1.5498 - val_accuracy: 0.4558\n",
      "Epoch 52/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 1.6314 - accuracy: 0.4285 - val_loss: 1.7891 - val_accuracy: 0.3429\n",
      "40/40 - 1s - loss: 1.2950 - accuracy: 0.5539\n",
      "Epoch 1/200\n",
      "196/196 [==============================] - 12s 55ms/step - loss: 3.3451 - accuracy: 0.1046 - val_loss: 2.3039 - val_accuracy: 0.1000\n",
      "Epoch 2/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 2.5650 - accuracy: 0.1095 - val_loss: 2.3041 - val_accuracy: 0.1000\n",
      "Epoch 3/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 2.4020 - accuracy: 0.1148 - val_loss: 2.3040 - val_accuracy: 0.1001\n",
      "Epoch 4/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 2.3510 - accuracy: 0.1341 - val_loss: 2.3062 - val_accuracy: 0.1002\n",
      "Epoch 5/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 2.2541 - accuracy: 0.1552 - val_loss: 2.3149 - val_accuracy: 0.1006\n",
      "Epoch 6/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 2.2210 - accuracy: 0.1599 - val_loss: 2.3330 - val_accuracy: 0.1035\n",
      "Epoch 7/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 2.1621 - accuracy: 0.1681 - val_loss: 2.3693 - val_accuracy: 0.1001\n",
      "Epoch 8/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 2.0976 - accuracy: 0.1733 - val_loss: 2.3983 - val_accuracy: 0.1005\n",
      "Epoch 9/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 2.0694 - accuracy: 0.1738 - val_loss: 2.3840 - val_accuracy: 0.1010\n",
      "Epoch 10/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 2.0507 - accuracy: 0.1760 - val_loss: 2.3960 - val_accuracy: 0.1012\n",
      "Epoch 11/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 2.0323 - accuracy: 0.1786 - val_loss: 2.4398 - val_accuracy: 0.1008\n",
      "40/40 - 1s - loss: 2.3039 - accuracy: 0.1000\n",
      "Epoch 1/200\n",
      "196/196 [==============================] - 12s 55ms/step - loss: 8.6637 - accuracy: 0.1027 - val_loss: 2.3053 - val_accuracy: 0.1000\n",
      "Epoch 2/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 3.0286 - accuracy: 0.1045 - val_loss: 2.3056 - val_accuracy: 0.1000\n",
      "Epoch 3/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 2.6764 - accuracy: 0.1043 - val_loss: 2.3044 - val_accuracy: 0.1000\n",
      "Epoch 4/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 2.4674 - accuracy: 0.0983 - val_loss: 2.3034 - val_accuracy: 0.1000\n",
      "Epoch 5/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 2.4066 - accuracy: 0.0997 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
      "Epoch 6/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 2.3676 - accuracy: 0.0981 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 7/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 2.3499 - accuracy: 0.0983 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 8/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 2.3401 - accuracy: 0.0978 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 9/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 2.3223 - accuracy: 0.0975 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 10/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 2.3305 - accuracy: 0.0981 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 11/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 2.3293 - accuracy: 0.0982 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 12/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 2.3358 - accuracy: 0.0976 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 13/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 2.3311 - accuracy: 0.0984 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 14/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 2.3205 - accuracy: 0.0982 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 15/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 2.3425 - accuracy: 0.0976 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 16/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 2.3122 - accuracy: 0.0982 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 17/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 2.3135 - accuracy: 0.0969 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 18/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 2.3097 - accuracy: 0.0984 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 19/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 2.3146 - accuracy: 0.0975 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 20/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 2.3092 - accuracy: 0.0972 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 21/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 2.3049 - accuracy: 0.0975 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 22/200\n",
      "196/196 [==============================] - 11s 53ms/step - loss: 2.3142 - accuracy: 0.0980 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 23/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 2.3115 - accuracy: 0.0981 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 24/200\n",
      "196/196 [==============================] - 11s 54ms/step - loss: 2.3293 - accuracy: 0.0967 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 25/200\n",
      "196/196 [==============================] - 10s 53ms/step - loss: 2.3077 - accuracy: 0.0979 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 26/200\n",
      "196/196 [==============================] - 10s 52ms/step - loss: 2.3105 - accuracy: 0.0987 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 27/200\n",
      "196/196 [==============================] - 10s 52ms/step - loss: 2.3049 - accuracy: 0.0965 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "40/40 - 1s - loss: 2.3026 - accuracy: 0.1000\n"
     ]
    }
   ],
   "source": [
    "history_list = []\n",
    "\n",
    "for num in range(1, 10):\n",
    "    model = getModel(num * 0.1)\n",
    "\n",
    "    model.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "                  optimizer=keras.optimizers.Adam(1e-3),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    hist = model.fit(train_ds, batch_size=nb_batch, epochs=nb_epochs,\n",
    "                     verbose=1, validation_data=test_ds,\n",
    "                     shuffle=True,\n",
    "                     callbacks=[callback])\n",
    "\n",
    "    test_loss, test_acc = model.evaluate(test_ds, verbose=2)\n",
    "    history_list.append([num*0.1, test_acc * 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dropout rate: 0.1, Test accuracy: 86.87%\n",
      "\n",
      "Dropout rate: 0.2, Test accuracy: 86.88%\n",
      "\n",
      "Dropout rate: 0.3, Test accuracy: 87.61%\n",
      "\n",
      "Dropout rate: 0.4, Test accuracy: 84.98%\n",
      "\n",
      "Dropout rate: 0.5, Test accuracy: 80.63%\n",
      "\n",
      "Dropout rate: 0.6, Test accuracy: 67.46%\n",
      "\n",
      "Dropout rate: 0.7, Test accuracy: 55.39%\n",
      "\n",
      "Dropout rate: 0.8, Test accuracy: 10.00%\n",
      "\n",
      "Dropout rate: 0.9, Test accuracy: 10.00%\n"
     ]
    }
   ],
   "source": [
    "for hist in history_list:\n",
    "    print('\\nDropout rate: {:0.1f}, Test accuracy: {:.2f}%'.format(\n",
    "        hist[0], hist[1]))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
